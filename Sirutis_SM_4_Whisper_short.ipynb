{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DkQxVSsfftfH",
        "s1yi4Ic3gyBl",
        "eZYxBuCegZ8n",
        "Uky8tZRzgr7t",
        "PF7pbnCegyyg",
        "cg-U1NHrg0Rz",
        "emsVUgekg1bv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASR. Распознование голосов спикеров."
      ],
      "metadata": {
        "id": "ebWYWVpocXT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Установка Whisper и считывание данных."
      ],
      "metadata": {
        "id": "DkQxVSsfftfH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpuCORYMbmkt",
        "outputId": "d1f9fdb1-cfd2-44db-91a0-957c1454ee56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801356 sha256=44cfa3a9055d4e69f02237b57e0321089dbf49bee1a7e0be580981c07a19c99e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install -U openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "for i, file_data in enumerate(files.upload().values()):\n",
        "  with open(f'{i}.wav', 'wb') as f:\n",
        "    f.write(file_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "PYAgA3zlcW2z",
        "outputId": "f396e5f8-c7a7-4e6d-9ab4-eddd10356fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-30264684-6394-4f46-b2b6-081640e0a22e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-30264684-6394-4f46-b2b6-081640e0a22e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Speaker_1_Segment_1.wav to Speaker_1_Segment_1.wav\n",
            "Saving Speaker_1_Segment_2.wav to Speaker_1_Segment_2.wav\n",
            "Saving Speaker_2_Segment_1.wav to Speaker_2_Segment_1.wav\n",
            "Saving Speaker_2_Segment_2.wav to Speaker_2_Segment_2.wav\n",
            "Saving Speaker_3_Segment_1.wav to Speaker_3_Segment_1.wav\n",
            "Saving Speaker_3_Segment_2.wav to Speaker_3_Segment_2.wav\n",
            "Saving Speaker_4_Segment_1.wav to Speaker_4_Segment_1.wav\n",
            "Saving Speaker_4_Segment_2.wav to Speaker_4_Segment_2.wav\n",
            "Saving Speaker_5_Segment_1.wav to Speaker_5_Segment_1.wav\n",
            "Saving Speaker_5_Segment_2.wav to Speaker_5_Segment_2.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Установка и создание функций"
      ],
      "metadata": {
        "id": "s1yi4Ic3gyBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3ROyj27XQrA",
        "outputId": "86852a26-c200-417d-a4ae-e3d47c374f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFm-aAh1qval",
        "outputId": "34651ac6-43da-4761-ffe7-f59dcee0e1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.3 rapidfuzz-3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import IPython\n",
        "import whisper\n",
        "import time\n"
      ],
      "metadata": {
        "id": "DwLOXQ2hfnyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import whisper\n",
        "#import time\n",
        "\n",
        "def whisper_trans(size='large-v2', file_name='0.wav'):\n",
        "  st_time = time.time()\n",
        "\n",
        "  model= whisper.load_model(size)\n",
        "  result = model.transcribe(file_name)\n",
        "  print('Результат: ', result[\"text\"], end='\\n')\n",
        "  print('Время обработки :', Time:=(time.time() - st_time), end='\\n\\n')\n",
        "  return result[\"text\"], Time"
      ],
      "metadata": {
        "id": "FDIR7CXKe9DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_wer(reference, hypothesis):\n",
        "\tref_words = reference.split()\n",
        "\thyp_words = hypothesis.split()\n",
        "\t# Counting the number of substitutions, deletions, and insertions\n",
        "\tsubstitutions = sum(1 for ref, hyp in zip(ref_words, hyp_words) if ref != hyp)\n",
        "\tdeletions = len(ref_words) - len(hyp_words)\n",
        "\tinsertions = len(hyp_words) - len(ref_words)\n",
        "\t# Total number of words in the reference text\n",
        "\ttotal_words = len(ref_words)\n",
        "\t# Calculating the Word Error Rate (WER)\n",
        "\twer = (substitutions + deletions + insertions) / total_words\n",
        "\treturn wer"
      ],
      "metadata": {
        "id": "cuNa-em0Bbfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cer(reference, hypothesis):\n",
        "    reference = list(reference)  # преобразуем строку в список символов\n",
        "    hypothesis = list(hypothesis)  # преобразуем строку в список символов\n",
        "    # Counting the number of substitutions, deletions, and insertions\n",
        "    substitutions = sum(1 for ref, hyp in zip(reference, hypothesis) if ref != hyp)\n",
        "    deletions = sum(1 for ref in reference if ref not in hypothesis)\n",
        "    insertions = sum(1 for hyp in hypothesis if hyp not in reference)\n",
        "    # Total number of characters in the reference text\n",
        "    total_characters = len(reference)\n",
        "    # Calculating the Character Error Rate (CER)\n",
        "    cer = (substitutions + deletions + insertions) / total_characters\n",
        "    return cer"
      ],
      "metadata": {
        "id": "X8yXdrC7rXM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "H9iEyAYk6kyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Спикер №1\n",
        "https://youtube.com/shorts/TUpZPzTzOEQ?si=fKn3ytsFVheOsVDY"
      ],
      "metadata": {
        "id": "eZYxBuCegZ8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначало прослушаем аудио и сделаем ручную транскрипцию."
      ],
      "metadata": {
        "id": "lC-5DGKypLkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "sMJhMVPmfCpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import IPython\n",
        "IPython.display.Audio('Speaker_1_Segment_1.wav')"
      ],
      "metadata": {
        "id": "_3EO_7yGfHdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_1_Segment_1 = ' Для теста соедини воду, соль, яйцо. Добавь муки, замеси тугое тесто. Накрой и оставь на 30 минут. А для начинки соедини мясо, лук, тыкву, соль, черный перец, паприку и кориандр. Тесто скатай тонко. Вырежь кругляшки с помощью пиалки. Клади начинку и формируй манты как на видео.'    # Ручная транскрипция спикера 1 и сегмента 1."
      ],
      "metadata": {
        "id": "wKVFsjfUpaA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Audio('Speaker_1_Segment_2.wav')"
      ],
      "metadata": {
        "id": "Abxt-WLDqnfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_1_Segment_2 = ' Вот такая красота получится. Листы пароварки смажь маслом, клади манты, вари на пару на сильном огне 40 минут. Безумно вкусные, шикарные манты получились. Сохраняй рецепт, ведь это нереальная вкуснятина.'    # Ручная транскрипция спикера 1 и сегмента 2."
      ],
      "metadata": {
        "id": "vaQZAu8vqpZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сделаем транскрипцию с whisper."
      ],
      "metadata": {
        "id": "zKoEuSVFpYkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_1_Segment_1_large_v2, time_Speaker_1_Segment_1_large_v2 = whisper_trans(file_name='Speaker_1_Segment_1.wav')\n",
        "\n",
        "text_Speaker_1_Segment_2_large_v2, time_Speaker_1_Segment_2_large_v2 = whisper_trans(file_name='Speaker_1_Segment_2.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUNKjjXPmGSA",
        "outputId": "3aa180cc-2317-4a6f-b086-bc24e68c1a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [01:01<00:00, 50.0MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Для теста соединяй воду, соль и яйцо. Добавь в муке, замеси тугое тесто. Накрой и оставь на 30 минут. А для начинки соединяй мясо, лук, тыкву, соль, черный перец, паприку и кориандр. Тесто скатай тонко. Вырежь круглишки с помощью пиалки. Клади начинку и формируй манты, как на видео.\n",
            "Время обработки : 335.9329471588135\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Вот такая красота получится! Листы пароварки смажем маслом, кладем манты, варим на сильном огне 40 минут. Безумно вкусные, шикарные манты получились! Сохраняй рецепт, ведь это нереально вкуснятина!\n",
            "Время обработки : 272.6830749511719\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_1_Segment_1_base, time_Speaker_1_Segment_1_base = whisper_trans(size='base', file_name='Speaker_1_Segment_1.wav')\n",
        "\n",
        "text_Speaker_1_Segment_2_base, time_Speaker_1_Segment_2_base = whisper_trans(size='base', file_name='Speaker_1_Segment_2.wav')"
      ],
      "metadata": {
        "id": "IFm8Gfzj4sAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c195c55a-7eb3-4470-d124-acab5600766d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 85.3MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Для теста соединяя воду, соль и цо, добавим в муке, самесит угое тесто. На крой я ставь на 30 минут, а для начинки соединяя мяса, лук, теку, соль, чё не перец, паприку и кориандр. Тесто скатает тонко, вырежешь кружки с помощью пялки, поди начинку и фармируем манты, как на видео.\n",
            "Время обработки : 14.325289726257324\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Вот такая красота получится. Если пара варки сможет маслом, в клади манты, варин на полу насилием огне 40 минут. Безумно вкусно, шикарные манты получились. Сохраняли цепь, питьята.\n",
            "Время обработки : 14.21870493888855\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_1_Segment_1  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №1, сегмент 1, модель = \"large_v2\": ', text_Speaker_1_Segment_1_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №1, сегмент 1, модель = \"base\"    : ', text_Speaker_1_Segment_1_base    , end='\\n\\n')\n",
        "\n",
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_1_Segment_2  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №1, сегмент 2, модель = \"large_v2\": ', text_Speaker_1_Segment_2_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №1, сегмент 2, модель = \"base\"    : ', text_Speaker_1_Segment_2_base    , end='\\n\\n')"
      ],
      "metadata": {
        "id": "eeo1XuIGcLKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263cb5c5-ecc7-4753-9dd5-ddff64f01426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ручная транскрипция для данного спикера                        :   Для теста соедини воду, соль, яйцо. Добавь муки, замеси тугое тесто. Накрой и оставь на 30 минут. А для начинки соедини мясо, лук, тыкву, соль, черный перец, паприку и кориандр. Тесто скатай тонко. Вырежь кругляшки с помощью пиалки. Клади начинку и формируй манты как на видео.\n",
            "Транскрипция Whisper спикера №1, сегмент 1, модель = \"large_v2\":   Для теста соединяй воду, соль и яйцо. Добавь в муке, замеси тугое тесто. Накрой и оставь на 30 минут. А для начинки соединяй мясо, лук, тыкву, соль, черный перец, паприку и кориандр. Тесто скатай тонко. Вырежь круглишки с помощью пиалки. Клади начинку и формируй манты, как на видео.\n",
            "Транскрипция Whisper спикера №1, сегмент 1, модель = \"base\"    :   Для теста соединяя воду, соль и цо, добавим в муке, самесит угое тесто. На крой я ставь на 30 минут, а для начинки соединяя мяса, лук, теку, соль, чё не перец, паприку и кориандр. Тесто скатает тонко, вырежешь кружки с помощью пялки, поди начинку и фармируем манты, как на видео.\n",
            "\n",
            "Ручная транскрипция для данного спикера                        :   Вот такая красота получится. Листы пароварки смажь маслом, клади манты, вари на пару на сильном огне 40 минут. Безумно вкусные, шикарные манты получились. Сохраняй рецепт, ведь это нереальная вкуснятина.\n",
            "Транскрипция Whisper спикера №1, сегмент 2, модель = \"large_v2\":   Вот такая красота получится! Листы пароварки смажем маслом, кладем манты, варим на сильном огне 40 минут. Безумно вкусные, шикарные манты получились! Сохраняй рецепт, ведь это нереально вкуснятина!\n",
            "Транскрипция Whisper спикера №1, сегмент 2, модель = \"base\"    :   Вот такая красота получится. Если пара варки сможет маслом, в клади манты, варин на полу насилием огне 40 минут. Безумно вкусно, шикарные манты получились. Сохраняли цепь, питьята.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь посчитаем метрики Word Error Rate и Character Error Rate."
      ],
      "metadata": {
        "id": "1WxIrfbGABTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_Speker_1_Segment_1_large_v2 = calculate_wer(reference=text_manual_Speaker_1_Segment_1, hypothesis=text_Speaker_1_Segment_1_large_v2)\n",
        "wer_Speker_1_Segment_2_large_v2 = calculate_wer(reference=text_manual_Speaker_1_Segment_2, hypothesis=text_Speaker_1_Segment_2_large_v2)\n",
        "\n",
        "wer_Speker_1_Segment_1_base = calculate_wer(reference=text_manual_Speaker_1_Segment_1, hypothesis=text_Speaker_1_Segment_1_base)\n",
        "wer_Speker_1_Segment_2_base = calculate_wer(reference=text_manual_Speaker_1_Segment_2, hypothesis=text_Speaker_1_Segment_2_base)"
      ],
      "metadata": {
        "id": "ePdsv1iuQtq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cer_Speker_1_Segment_1_large_v2 = calculate_cer(reference=text_manual_Speaker_1_Segment_1, hypothesis=text_Speaker_1_Segment_1_large_v2)\n",
        "cer_Speker_1_Segment_2_large_v2 = calculate_cer(reference=text_manual_Speaker_1_Segment_2, hypothesis=text_Speaker_1_Segment_2_large_v2)\n",
        "\n",
        "cer_Speker_1_Segment_1_base = calculate_cer(reference=text_manual_Speaker_1_Segment_1, hypothesis=text_Speaker_1_Segment_1_base)\n",
        "cer_Speker_1_Segment_2_base = calculate_cer(reference=text_manual_Speaker_1_Segment_2, hypothesis=text_Speaker_1_Segment_2_base)\n"
      ],
      "metadata": {
        "id": "eqnBLJf-X-Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Error Rate\n",
        "print('WER cer_Speker_1_Segment_1_large_v2 := ', wer_Speker_1_Segment_1_large_v2, end='\\n')\n",
        "print('WER cer_Speker_1_Segment_2_large_v2 := ', wer_Speker_1_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('WER cer_Speker_1_Segment_1_base := ', wer_Speker_1_Segment_1_base, end='\\n')\n",
        "print('WER cer_Speker_1_Segment_2_base := ', wer_Speker_1_Segment_2_base, end='\\n\\n')\n",
        "\n",
        "#Character Error Rate\n",
        "print('CER cer_Speker_1_Segment_1_large_v2 := ', cer_Speker_1_Segment_1_large_v2, end='\\n')\n",
        "print('CER cer_Speker_1_Segment_2_large_v2 := ', cer_Speker_1_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('CER cer_Speker_1_Segment_1_base := ', cer_Speker_1_Segment_1_base, end='\\n')\n",
        "print('CER cer_Speker_1_Segment_2_base := ', cer_Speker_1_Segment_2_base, end='\\n\\n')"
      ],
      "metadata": {
        "id": "wM2ZQuqTAaw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604fa17c-6c63-4ec2-9b08-05394252782b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER cer_Speker_1_Segment_1_large_v2 :=  0.9347826086956522\n",
            "WER cer_Speker_1_Segment_2_large_v2 :=  0.6551724137931034\n",
            "\n",
            "WER cer_Speker_1_Segment_1_base :=  0.9347826086956522\n",
            "WER cer_Speker_1_Segment_2_base :=  0.7586206896551724\n",
            "\n",
            "CER cer_Speker_1_Segment_1_large_v2 :=  0.89568345323741\n",
            "CER cer_Speker_1_Segment_2_large_v2 :=  0.7205882352941176\n",
            "\n",
            "CER cer_Speker_1_Segment_1_base :=  0.8093525179856115\n",
            "CER cer_Speker_1_Segment_2_base :=  0.6862745098039216\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KYii8VtYfizP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Спикер №2\n",
        "https://youtube.com/shorts/TT5Fwa_zwgc?si=x4sabkD9BF1PldE8"
      ],
      "metadata": {
        "id": "Uky8tZRzgr7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначало прослушаем аудио и сделаем ручную транскрипцию."
      ],
      "metadata": {
        "id": "tySfbZwAgr7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "1zzicKYGgr7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import IPython\n",
        "IPython.display.Audio('Speaker_2_Segment_1.wav')"
      ],
      "metadata": {
        "id": "RYQVkk6pgr7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_2_Segment_1 = ' Женщина засняла, как ее муж проснулся рано утром в первый день, когда выпал снег, чтоб написать на нем «доброе утро», чтобы их дети могли увидеть эту надпись, когда проснутся. Он даже успел нарисовать семейную фотографию, а жена умилено наблюдала за его творчеством. '    # Ручная транскрипция спикера 1 и сегмента 1."
      ],
      "metadata": {
        "id": "hlVMRT4Ogr7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Audio('Speaker_2_Segment_2.wav')"
      ],
      "metadata": {
        "id": "Y3Mhjh2xgr7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_2_Segment_2 = ' После того, как он закончил надпись, ему пришлось аккуратно вернуться обратно, чтобы не оставить на снегу следов, которые могли бы всё испортить. Он немного постоял, думая, что наконец-то всё готово, а потом вспомнил, что нужно добавить ещё кое-что и нарисовал рядышком сердечко. Такие простые поступки нам напоминают, что даже в повседневных и незначительных моментах мы можем выразить нашу любовь и заботу.'    # Ручная транскрипция спикера 1 и сегмента 2."
      ],
      "metadata": {
        "id": "guO4KPE2gr7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сделаем транскрипцию с whisper."
      ],
      "metadata": {
        "id": "jMmNcxR6gr7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_2_Segment_1_large_v2, time_Speaker_2_Segment_1_large_v2 = whisper_trans(file_name='Speaker_2_Segment_1.wav')\n",
        "\n",
        "text_Speaker_2_Segment_2_large_v2, time_Speaker_2_Segment_2_large_v2 = whisper_trans(file_name='Speaker_2_Segment_2.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55478ad2-f5d9-47e7-b1cd-7fadc1c6441e",
        "id": "q8-uKu49gr7w"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Женщина засняла, как ее муж проснулся рано утром, в первый день, когда выпал снег, чтобы написать на нем «Доброе утро», чтобы их дети могли увидеть эту надпись, когда проснутся. Он даже успел нарисовать семейную фотографию. А жена умиленно наблюдала за его творчеством.\n",
            "Время обработки : 256.0473139286041\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   После того, как он закончил надпись, ему пришлось аккуратно вернуться обратно, чтобы не оставить на снегу следов, которые могли бы все испортить. Он немного постоял, думая, что наконец-то все готово, а потом вспомнил, что нужно добавить еще кое-что, и нарисовал рядышком сердечко. Такие простые поступки нам напоминают, что даже в повседневных и незначительных моментах мы можем выразить нашу любовь и заботу.\n",
            "Время обработки : 292.34000539779663\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_2_Segment_1_base, time_Speaker_2_Segment_1_base = whisper_trans(size='base', file_name='Speaker_2_Segment_1.wav')\n",
        "\n",
        "text_Speaker_2_Segment_2_base, time_Speaker_2_Segment_2_base = whisper_trans(size='base', file_name='Speaker_2_Segment_2.wav')"
      ],
      "metadata": {
        "id": "Yj8nqZptgr7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dbf2b49-d0a9-474c-f6d3-ee5ddf51b2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Женщина засняла, как ее муж проснулся рано утром, в первый день, когда выпал снег. Чтобы написать на нем доброе утро, чтобы их дети могли увидеть эту напись, когда проснуться. Он даже успел нарисовать семейную фотографию. А жена у миллиона наблюдала за его творчеством.\n",
            "Время обработки : 16.873456716537476\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   После того, как он закончил надпись, ему пришлось аккуратно вернуться обратно, чтобы не оставить на снегу следов, который могли бы всё испортить. Он немного постоял, думая, что наконец-то всё готово. А потом вспомнил, что нужно добавить ещё кое-что и нарисовал рядышком сердечко. Такие простые поступки нам напоминают, что даже в повседневных и незначительных моментах мы можем выразить нашу любовь и заботу.\n",
            "Время обработки : 14.429059028625488\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_2_Segment_1  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №2, сегмент 1, модель = \"large_v2\": ', text_Speaker_2_Segment_1_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №2, сегмент 1, модель = \"base\"    : ', text_Speaker_2_Segment_1_base    , end='\\n\\n')\n",
        "\n",
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_2_Segment_2  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №2, сегмент 2, модель = \"large_v2\": ', text_Speaker_2_Segment_2_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №2, сегмент 2, модель = \"base\"    : ', text_Speaker_2_Segment_2_base    , end='\\n\\n')"
      ],
      "metadata": {
        "id": "mnXfxLqFgr7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b2e2c2-6c04-4cfe-aa87-f5413a23ff1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ручная транскрипция для данного спикера                        :   Женщина засняла, как ее муж проснулся рано утром в первый день, когда выпал снег, чтоб написать на нем «доброе утро», чтобы их дети могли увидеть эту надпись, когда проснутся. Он даже успел нарисовать семейную фотографию, а жена умилено наблюдала за его творчеством. \n",
            "Транскрипция Whisper спикера №2, сегмент 1, модель = \"large_v2\":   Женщина засняла, как ее муж проснулся рано утром, в первый день, когда выпал снег, чтобы написать на нем «Доброе утро», чтобы их дети могли увидеть эту надпись, когда проснутся. Он даже успел нарисовать семейную фотографию. А жена умиленно наблюдала за его творчеством.\n",
            "Транскрипция Whisper спикера №2, сегмент 1, модель = \"base\"    :   Женщина засняла, как ее муж проснулся рано утром, в первый день, когда выпал снег. Чтобы написать на нем доброе утро, чтобы их дети могли увидеть эту напись, когда проснуться. Он даже успел нарисовать семейную фотографию. А жена у миллиона наблюдала за его творчеством.\n",
            "\n",
            "Ручная транскрипция для данного спикера                        :   После того, как он закончил надпись, ему пришлось аккуратно вернуться обратно, чтобы не оставить на снегу следов, которые могли бы всё испортить. Он немного постоял, думая, что наконец-то всё готово, а потом вспомнил, что нужно добавить ещё кое-что и нарисовал рядышком сердечко. Такие простые поступки нам напоминают, что даже в повседневных и незначительных моментах мы можем выразить нашу любовь и заботу.\n",
            "Транскрипция Whisper спикера №2, сегмент 2, модель = \"large_v2\":   После того, как он закончил надпись, ему пришлось аккуратно вернуться обратно, чтобы не оставить на снегу следов, которые могли бы все испортить. Он немного постоял, думая, что наконец-то все готово, а потом вспомнил, что нужно добавить еще кое-что, и нарисовал рядышком сердечко. Такие простые поступки нам напоминают, что даже в повседневных и незначительных моментах мы можем выразить нашу любовь и заботу.\n",
            "Транскрипция Whisper спикера №2, сегмент 2, модель = \"base\"    :   После того, как он закончил надпись, ему пришлось аккуратно вернуться обратно, чтобы не оставить на снегу следов, который могли бы всё испортить. Он немного постоял, думая, что наконец-то всё готово. А потом вспомнил, что нужно добавить ещё кое-что и нарисовал рядышком сердечко. Такие простые поступки нам напоминают, что даже в повседневных и незначительных моментах мы можем выразить нашу любовь и заботу.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь посчитаем метрики Word Error Rate и Character Error Rate."
      ],
      "metadata": {
        "id": "o8AeRFwjgr7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_Speker_2_Segment_1_large_v2 = calculate_wer(reference=text_manual_Speaker_2_Segment_1, hypothesis=text_Speaker_2_Segment_1_large_v2)\n",
        "wer_Speker_2_Segment_2_large_v2 = calculate_wer(reference=text_manual_Speaker_2_Segment_2, hypothesis=text_Speaker_2_Segment_2_large_v2)\n",
        "\n",
        "wer_Speker_2_Segment_1_base = calculate_wer(reference=text_manual_Speaker_2_Segment_1, hypothesis=text_Speaker_2_Segment_1_base)\n",
        "wer_Speker_2_Segment_2_base = calculate_wer(reference=text_manual_Speaker_2_Segment_2, hypothesis=text_Speaker_2_Segment_2_base)"
      ],
      "metadata": {
        "id": "8KTheuZUgr7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cer_Speker_2_Segment_1_large_v2 = calculate_cer(reference=text_manual_Speaker_2_Segment_1, hypothesis=text_Speaker_2_Segment_1_large_v2)\n",
        "\n",
        "cer_Speker_2_Segment_2_large_v2 = calculate_cer(reference=text_manual_Speaker_2_Segment_2, hypothesis=text_Speaker_2_Segment_2_large_v2)\n",
        "\n",
        "\n",
        "cer_Speker_2_Segment_1_base = calculate_cer(reference=text_manual_Speaker_2_Segment_1, hypothesis=text_Speaker_2_Segment_1_base)\n",
        "\n",
        "cer_Speker_2_Segment_2_base = calculate_cer(reference=text_manual_Speaker_2_Segment_2, hypothesis=text_Speaker_2_Segment_2_base)\n"
      ],
      "metadata": {
        "id": "4I4zKvr4gr7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Error Rate\n",
        "print('WER cer_Speker_2_Segment_1_large_v2 := ', wer_Speker_2_Segment_1_large_v2, end='\\n')\n",
        "print('WER cer_Speker_2_Segment_2_large_v2 := ', wer_Speker_2_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('WER cer_Speker_2_Segment_1_base := ', wer_Speker_2_Segment_1_base, end='\\n')\n",
        "print('WER cer_Speker_2_Segment_2_base := ', wer_Speker_2_Segment_2_base, end='\\n\\n')\n",
        "\n",
        "#Character Error Rate\n",
        "print('CER cer_Speker_2_Segment_1_large_v2 := ', cer_Speker_2_Segment_1_large_v2, end='\\n')\n",
        "print('CER cer_Speker_2_Segment_2_large_v2 := ', cer_Speker_2_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('CER cer_Speker_2_Segment_1_base := ', cer_Speker_2_Segment_1_base, end='\\n')\n",
        "print('CER cer_Speker_2_Segment_2_base := ', cer_Speker_2_Segment_2_base, end='\\n\\n')"
      ],
      "metadata": {
        "id": "KvlG7oyQgr7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18ae936-ed9c-46b2-b994-54092aa4141a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER cer_Speker_2_Segment_1_large_v2 :=  0.14285714285714285\n",
            "WER cer_Speker_2_Segment_2_large_v2 :=  0.06557377049180328\n",
            "\n",
            "WER cer_Speker_2_Segment_1_base :=  0.3333333333333333\n",
            "WER cer_Speker_2_Segment_2_base :=  0.04918032786885246\n",
            "\n",
            "CER cer_Speker_2_Segment_1_large_v2 :=  0.8022388059701493\n",
            "CER cer_Speker_2_Segment_2_large_v2 :=  0.4058679706601467\n",
            "\n",
            "CER cer_Speker_2_Segment_1_base :=  0.47388059701492535\n",
            "CER cer_Speker_2_Segment_2_base :=  0.012224938875305624\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для понимания – чем ближе к нулю показатели WER и CER, тем лучше работает система."
      ],
      "metadata": {
        "id": "o6IYaubu6kBd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CygZ6ZLUgr7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Спикер №3\n",
        "https://youtu.be/nQ9-QK-ps24?si=oOBfWbT0d1qBHMNo"
      ],
      "metadata": {
        "id": "PF7pbnCegyyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначало прослушаем аудио и сделаем ручную транскрипцию."
      ],
      "metadata": {
        "id": "LIk8DQjfgyyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Gl7qXSvbgyyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import IPython\n",
        "IPython.display.Audio('Speaker_3_Segment_1.wav')"
      ],
      "metadata": {
        "id": "GMFWeophgyyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_3_Segment_1 = ' Друзья мои, всем привет. С вами Дина и канал «Коллекция рецептов». Какой же новый год и рождество без ёлки, мандаринов и традиционной рождественской выпечки: кексы, штоллены, пряники, цитрусовые десерты, разнообразное печенье в виде домиков, шишек,  снежинок, пряничных человечков.'    # Ручная транскрипция спикера 1 и сегмента 1."
      ],
      "metadata": {
        "id": "KCdfP0G5gyys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Audio('Speaker_3_Segment_2.wav')"
      ],
      "metadata": {
        "id": "v8YOjnBYgyys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_3_Segment_2 = ' По одному разбиваем два яйца, каждый раз хорошо вмешивая их в масляную смесь. Следом добавляем 60 граммов меда – это две столовые ложки и смешиваем всё вместе.'    # Ручная транскрипция спикера 1 и сегмента 2."
      ],
      "metadata": {
        "id": "vYeKcz_Ogyyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сделаем транскрипцию с whisper."
      ],
      "metadata": {
        "id": "O9R8FUtqgyyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_3_Segment_1_large_v2, time_Speaker_3_Segment_1_large_v2 = whisper_trans(file_name='Speaker_3_Segment_1.wav')\n",
        "\n",
        "text_Speaker_3_Segment_2_large_v2, time_Speaker_3_Segment_2_large_v2 = whisper_trans(file_name='Speaker_3_Segment_2.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0e657c-ef0c-4a96-c640-d3b6b38b8ef9",
        "id": "exEFZ0WJgyyt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Друзья мои, всем привет! С вами Дина и канал Коллекция Рецептов. Какой же Новый Год и Рождество без елки, мандаринов и традиционной рождественской выпечки? Кексы, штолины, пряники, цитрусовые десерты, разнообразное печенье в виде домиков, шишек, снежинок, пряничных человечков.\n",
            "Время обработки : 259.0766065120697\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   По одному разбиваем два яйца, каждый раз хорошо вмешивая их в масляную смесь. Следом добавляем 60 граммов меда, это 2 столовые ложки и смешиваем все вместе.\n",
            "Время обработки : 223.80612444877625\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_3_Segment_1_base, time_Speaker_3_Segment_1_base = whisper_trans(size='base', file_name='Speaker_3_Segment_1.wav')\n",
        "\n",
        "text_Speaker_3_Segment_2_base, time_Speaker_3_Segment_2_base = whisper_trans(size='base', file_name='Speaker_3_Segment_2.wav')"
      ],
      "metadata": {
        "id": "E9pPVmAtgyyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbf5ac2-ed6d-4839-ce15-f1ea89c116ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Друзья мои всем привет! С вами Дина и канал коллекция рецептов. Какой же новый год и рождество без ёлки, мандаринов и традиционной рождественской выпечки? Кексы, что лины, пряники, цитрусовые десерты, разнообразное печение видедомиков, шишек, снижи, нак прянечных человечков.\n",
            "Время обработки : 13.63967227935791\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Падному разбиваем 2 яйца. Каждый раз хорошо вмешиваем их в масленную смесь. Следом добавляем 60 граммов меда. Это две столовые ложки и смешиваем все вместе.\n",
            "Время обработки : 9.315034866333008\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_3_Segment_1  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №3, сегмент 1, модель = \"large_v2\": ', text_Speaker_3_Segment_1_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №3, сегмент 1, модель = \"base\"    : ', text_Speaker_3_Segment_1_base    , end='\\n\\n')\n",
        "\n",
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_3_Segment_2  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №3, сегмент 2, модель = \"large_v2\": ', text_Speaker_3_Segment_2_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №3, сегмент 2, модель = \"base\"    : ', text_Speaker_3_Segment_2_base    , end='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fr8Lhvz-_Mf",
        "outputId": "21ee4bb8-ee35-404c-b334-72f6ee6957c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ручная транскрипция для данного спикера                        :   Друзья мои, всем привет. С вами Дина и канал «Коллекция рецептов». Какой же новый год и рождество без ёлки, мандаринов и традиционной рождественской выпечки: кексы, штоллены, пряники, цитрусовые десерты, разнообразное печенье в виде домиков, шишек,  снежинок, пряничных человечков.\n",
            "Транскрипция Whisper спикера №3, сегмент 1, модель = \"large_v2\":   Друзья мои, всем привет! С вами Дина и канал Коллекция Рецептов. Какой же Новый Год и Рождество без елки, мандаринов и традиционной рождественской выпечки? Кексы, штолины, пряники, цитрусовые десерты, разнообразное печенье в виде домиков, шишек, снежинок, пряничных человечков.\n",
            "Транскрипция Whisper спикера №3, сегмент 1, модель = \"base\"    :   Друзья мои всем привет! С вами Дина и канал коллекция рецептов. Какой же новый год и рождество без ёлки, мандаринов и традиционной рождественской выпечки? Кексы, что лины, пряники, цитрусовые десерты, разнообразное печение видедомиков, шишек, снижи, нак прянечных человечков.\n",
            "\n",
            "Ручная транскрипция для данного спикера                        :   По одному разбиваем два яйца, каждый раз хорошо вмешивая их в масляную смесь. Следом добавляем 60 граммов меда – это две столовые ложки и смешиваем всё вместе.\n",
            "Транскрипция Whisper спикера №3, сегмент 2, модель = \"large_v2\":   По одному разбиваем два яйца, каждый раз хорошо вмешивая их в масляную смесь. Следом добавляем 60 граммов меда, это 2 столовые ложки и смешиваем все вместе.\n",
            "Транскрипция Whisper спикера №3, сегмент 2, модель = \"base\"    :   Падному разбиваем 2 яйца. Каждый раз хорошо вмешиваем их в масленную смесь. Следом добавляем 60 граммов меда. Это две столовые ложки и смешиваем все вместе.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь посчитаем метрики Word Error Rate и Character Error Rate."
      ],
      "metadata": {
        "id": "FdPCOlokgyyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_Speker_3_Segment_1_large_v2 = calculate_wer(reference=text_manual_Speaker_3_Segment_1, hypothesis=text_Speaker_3_Segment_1_large_v2)\n",
        "wer_Speker_3_Segment_2_large_v2 = calculate_wer(reference=text_manual_Speaker_3_Segment_2, hypothesis=text_Speaker_3_Segment_2_large_v2)\n",
        "\n",
        "wer_Speker_3_Segment_1_base = calculate_wer(reference=text_manual_Speaker_3_Segment_1, hypothesis=text_Speaker_3_Segment_1_base)\n",
        "wer_Speker_3_Segment_2_base = calculate_wer(reference=text_manual_Speaker_3_Segment_2, hypothesis=text_Speaker_3_Segment_2_base)"
      ],
      "metadata": {
        "id": "7vAnfL-wgyyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cer_Speker_3_Segment_1_large_v2 = calculate_cer(reference=text_manual_Speaker_3_Segment_1, hypothesis=text_Speaker_3_Segment_1_large_v2)\n",
        "\n",
        "cer_Speker_3_Segment_2_large_v2 = calculate_cer(reference=text_manual_Speaker_3_Segment_2, hypothesis=text_Speaker_3_Segment_2_large_v2)\n",
        "\n",
        "\n",
        "cer_Speker_3_Segment_1_base = calculate_cer(reference=text_manual_Speaker_3_Segment_1, hypothesis=text_Speaker_3_Segment_1_base)\n",
        "\n",
        "cer_Speker_3_Segment_2_base = calculate_cer(reference=text_manual_Speaker_3_Segment_2, hypothesis=text_Speaker_3_Segment_2_base)\n"
      ],
      "metadata": {
        "id": "eC2l5tJOgyyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Error Rate\n",
        "print('WER cer_Speker_3_Segment_1_large_v2 := ', wer_Speker_3_Segment_1_large_v2, end='\\n')\n",
        "print('WER cer_Speker_3_Segment_2_large_v2 := ', wer_Speker_3_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('WER cer_Speker_3_Segment_1_base := ', wer_Speker_3_Segment_1_base, end='\\n')\n",
        "print('WER cer_Speker_3_Segment_2_base := ', wer_Speker_3_Segment_2_base, end='\\n\\n')\n",
        "\n",
        "#Character Error Rate\n",
        "print('CER cer_Speker_3_Segment_1_large_v2 := ', cer_Speker_3_Segment_1_large_v2, end='\\n')\n",
        "print('CER cer_Speker_3_Segment_2_large_v2 := ', cer_Speker_3_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('CER cer_Speker_3_Segment_1_base := ', cer_Speker_3_Segment_1_base, end='\\n')\n",
        "print('CER cer_Speker_3_Segment_2_base := ', cer_Speker_3_Segment_2_base, end='\\n\\n')"
      ],
      "metadata": {
        "id": "4bvbu_PXgyyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7eca44-6c07-4e39-93de-844eea1d85f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER cer_Speker_3_Segment_1_large_v2 :=  0.2631578947368421\n",
            "WER cer_Speker_3_Segment_2_large_v2 :=  0.3333333333333333\n",
            "\n",
            "WER cer_Speker_3_Segment_1_base :=  0.47368421052631576\n",
            "WER cer_Speker_3_Segment_2_base :=  0.9259259259259259\n",
            "\n",
            "CER cer_Speker_3_Segment_1_large_v2 :=  0.8262411347517731\n",
            "CER cer_Speker_3_Segment_2_large_v2 :=  0.3\n",
            "\n",
            "CER cer_Speker_3_Segment_1_base :=  0.925531914893617\n",
            "CER cer_Speker_3_Segment_2_base :=  0.975\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G-Db4zWBgyyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Спикер №4\n",
        "https://www.youtube.com/watch?v=M8fhrtvedHA"
      ],
      "metadata": {
        "id": "cg-U1NHrg0Rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначало прослушаем аудио и сделаем ручную транскрипцию."
      ],
      "metadata": {
        "id": "NyGmSBhdg0SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "omaNhvnEg0SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import IPython\n",
        "IPython.display.Audio('Speaker_4_Segment_1.wav')"
      ],
      "metadata": {
        "id": "Kqa6Kw8Rg0SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_4_Segment_1 = 'Окей первое, что мы с вами сделаем, напишем простейший эхо-бот, который будет просто возвращать всё, что ему напишут в личку словно какой-то попугай. Но для этого нам надо сначала установить библиотеку PY telegram-бот API и сразу скажу- это не самая крутая библиотека в Phyton для работы с Telegram API. Зато ей легко пользоваться и именно с неё я считаю стоить начинать учиться разрабатывать ботов.'    # Ручная транскрипция спикера 1 и сегмента 1."
      ],
      "metadata": {
        "id": "T_AHmYvkg0SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Audio('Speaker_4_Segment_2.wav')"
      ],
      "metadata": {
        "id": "Z0fqEpcQg0SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_4_Segment_2 = ' Кто хочет научиться большему прямо сейчас советую пойти и посмотреть. В остальном я жду ваш Царский лайк. Конечно же подписывайтесь на канал и включайте колокольчик уведомлений, так мои выпуски хоть иногда да будут появляться у вас на главной Ютуба. Удачи и всегда помните автоматизация действий - это круто.'    # Ручная транскрипция спикера 1 и сегмента 2."
      ],
      "metadata": {
        "id": "v33UG6cEg0SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сделаем транскрипцию с whisper."
      ],
      "metadata": {
        "id": "2-YsZhnGg0SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_4_Segment_1_large_v2, time_Speaker_4_Segment_1_large_v2 = whisper_trans(file_name='Speaker_4_Segment_1.wav')\n",
        "\n",
        "text_Speaker_4_Segment_2_large_v2, time_Speaker_4_Segment_2_large_v2 = whisper_trans(file_name='Speaker_4_Segment_2.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efef0f0c-3c93-426d-9a7c-1110582fcf54",
        "id": "zPjQEgoNg0SS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Окей, первое что мы с вами сделаем, напишем простейший эхо-бот, который будет просто возвращать всё, что ему напишут в личку, словно какой-то попугай. Но для этого нам надо сначала установить библиотеку PyTelegramBot.api. И сразу скажу, это не самая крутая библиотека в Python для работы с Telegram API, зато ей легко пользоваться, и именно с неё, я считаю, стоит начинать учиться разрабатывать ботов.\n",
            "Время обработки : 319.6638970375061\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   хочет научиться большему прямо сейчас, советую пойти и посмотреть. В остальном, я жду ваш царский лайк, конечно же подписывайтесь на канал и включайте колокольчик уведомлений, так мои выпуски хоть иногда да будут появляться у вас на главной ютуба. Удачи и всегда помните, автоматизация действий это круто!\n",
            "Время обработки : 236.10515570640564\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_4_Segment_1_base, time_Speaker_4_Segment_1_base = whisper_trans(size='base', file_name='Speaker_4_Segment_1.wav')\n",
        "\n",
        "text_Speaker_4_Segment_2_base, time_Speaker_4_Segment_2_base = whisper_trans(size='base', file_name='Speaker_4_Segment_2.wav')"
      ],
      "metadata": {
        "id": "DKfxHaSig0SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd331502-90ae-45b5-bd33-cb23f33c9a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Окей, первое что мы с вами сделаем, напишем простейший эхобот, который будет просто возвращать все, что ему напишут в личку словно какой-то пополгай. Но для этого нам надо сначала установить библиотеку по телеграм-бот-опи. Я сразу скажу это не самое крутое библиотеков по-тин для работы телеграм-опи. Зато ей легко пользоваться и именно с нее я считаю стоит начать учиться разрабатывать ботов.\n",
            "Время обработки : 14.74582052230835\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   что хочет научиться большему прямо сейчас, советую пойти и посмотреть. А в остальном я жду ваш царский лайк, конечно же подписывайтесь на канал и включайте колокольчиковидомлений. Так мои выпуски хоть иногда дабут, появятся у вас на главной ютуба. Удачи и всегда помните, автоматизация действий – это круто!\n",
            "Время обработки : 11.569579362869263\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_4_Segment_1  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №4, сегмент 1, модель = \"large_v2\": ', text_Speaker_4_Segment_1_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №4, сегмент 1, модель = \"base\"    : ', text_Speaker_4_Segment_1_base    , end='\\n\\n')\n",
        "\n",
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_4_Segment_2  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №4, сегмент 2, модель = \"large_v2\": ', text_Speaker_4_Segment_2_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №4, сегмент 2, модель = \"base\"    : ', text_Speaker_4_Segment_2_base    , end='\\n\\n')"
      ],
      "metadata": {
        "id": "vm51YrgHg0ST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26fb094-cd1d-4b4a-8ecd-ef8c9f80224c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ручная транскрипция для данного спикера                        :  Окей первое, что мы с вами сделаем, напишем простейший эхо-бот, который будет просто возвращать всё, что ему напишут в личку словно какой-то попугай. Но для этого нам надо сначала установить библиотеку PY telegram-бот API и сразу скажу- это не самая крутая библиотека в Phyton для работы с Telegram API. Зато ей легко пользоваться и именно с неё я считаю стоить начинать учиться разрабатывать ботов.\n",
            "Транскрипция Whisper спикера №4, сегмент 1, модель = \"large_v2\":   Окей, первое что мы с вами сделаем, напишем простейший эхо-бот, который будет просто возвращать всё, что ему напишут в личку, словно какой-то попугай. Но для этого нам надо сначала установить библиотеку PyTelegramBot.api. И сразу скажу, это не самая крутая библиотека в Python для работы с Telegram API, зато ей легко пользоваться, и именно с неё, я считаю, стоит начинать учиться разрабатывать ботов.\n",
            "Транскрипция Whisper спикера №4, сегмент 1, модель = \"base\"    :   Окей, первое что мы с вами сделаем, напишем простейший эхобот, который будет просто возвращать все, что ему напишут в личку словно какой-то пополгай. Но для этого нам надо сначала установить библиотеку по телеграм-бот-опи. Я сразу скажу это не самое крутое библиотеков по-тин для работы телеграм-опи. Зато ей легко пользоваться и именно с нее я считаю стоит начать учиться разрабатывать ботов.\n",
            "\n",
            "Ручная транскрипция для данного спикера                        :   Кто хочет научиться большему прямо сейчас советую пойти и посмотреть. В остальном я жду ваш Царский лайк. Конечно же подписывайтесь на канал и включайте колокольчик уведомлений, так мои выпуски хоть иногда да будут появляться у вас на главной Ютуба. Удачи и всегда помните автоматизация действий - это круто.\n",
            "Транскрипция Whisper спикера №4, сегмент 2, модель = \"large_v2\":   хочет научиться большему прямо сейчас, советую пойти и посмотреть. В остальном, я жду ваш царский лайк, конечно же подписывайтесь на канал и включайте колокольчик уведомлений, так мои выпуски хоть иногда да будут появляться у вас на главной ютуба. Удачи и всегда помните, автоматизация действий это круто!\n",
            "Транскрипция Whisper спикера №4, сегмент 2, модель = \"base\"    :   что хочет научиться большему прямо сейчас, советую пойти и посмотреть. А в остальном я жду ваш царский лайк, конечно же подписывайтесь на канал и включайте колокольчиковидомлений. Так мои выпуски хоть иногда дабут, появятся у вас на главной ютуба. Удачи и всегда помните, автоматизация действий – это круто!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь посчитаем метрики Word Error Rate и Character Error Rate."
      ],
      "metadata": {
        "id": "MbJAOo-yg0ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_Speker_4_Segment_1_large_v2 = calculate_wer(reference=text_manual_Speaker_4_Segment_1, hypothesis=text_Speaker_4_Segment_1_large_v2)\n",
        "wer_Speker_4_Segment_2_large_v2 = calculate_wer(reference=text_manual_Speaker_4_Segment_2, hypothesis=text_Speaker_4_Segment_2_large_v2)\n",
        "\n",
        "wer_Speker_4_Segment_1_base = calculate_wer(reference=text_manual_Speaker_4_Segment_1, hypothesis=text_Speaker_4_Segment_1_base)\n",
        "wer_Speker_4_Segment_2_base = calculate_wer(reference=text_manual_Speaker_4_Segment_2, hypothesis=text_Speaker_4_Segment_2_base)"
      ],
      "metadata": {
        "id": "aSAypxd1g0ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cer_Speker_4_Segment_1_large_v2 = calculate_cer(reference=text_manual_Speaker_4_Segment_1, hypothesis=text_Speaker_4_Segment_1_large_v2)\n",
        "\n",
        "cer_Speker_4_Segment_2_large_v2 = calculate_cer(reference=text_manual_Speaker_4_Segment_2, hypothesis=text_Speaker_4_Segment_2_large_v2)\n",
        "\n",
        "\n",
        "cer_Speker_4_Segment_1_base = calculate_cer(reference=text_manual_Speaker_4_Segment_1, hypothesis=text_Speaker_4_Segment_1_base)\n",
        "\n",
        "cer_Speker_4_Segment_2_base = calculate_cer(reference=text_manual_Speaker_4_Segment_2, hypothesis=text_Speaker_4_Segment_2_base)\n"
      ],
      "metadata": {
        "id": "Xk1Y0mRzg0SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Error Rate\n",
        "print('WER cer_Speker_4_Segment_1_large_v2 := ', wer_Speker_4_Segment_1_large_v2, end='\\n')\n",
        "print('WER cer_Speker_4_Segment_2_large_v2 := ', wer_Speker_4_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('WER cer_Speker_4_Segment_1_base := ', wer_Speker_4_Segment_1_base, end='\\n')\n",
        "print('WER cer_Speker_4_Segment_2_base := ', wer_Speker_4_Segment_2_base, end='\\n\\n')\n",
        "\n",
        "#Character Error Rate\n",
        "print('CER cer_Speker_4_Segment_1_large_v2 := ', cer_Speker_4_Segment_1_large_v2, end='\\n')\n",
        "print('CER cer_Speker_4_Segment_2_large_v2 := ', cer_Speker_4_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('CER cer_Speker_4_Segment_1_base := ', cer_Speker_4_Segment_1_base, end='\\n')\n",
        "print('CER cer_Speker_4_Segment_2_base := ', cer_Speker_4_Segment_2_base, end='\\n\\n')"
      ],
      "metadata": {
        "id": "e5zGxSs_g0SU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d502990-ff81-4dda-8bda-a7858d127e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER cer_Speker_4_Segment_1_large_v2 :=  0.53125\n",
            "WER cer_Speker_4_Segment_2_large_v2 :=  0.9583333333333334\n",
            "\n",
            "WER cer_Speker_4_Segment_1_base :=  0.53125\n",
            "WER cer_Speker_4_Segment_2_base :=  0.7291666666666666\n",
            "\n",
            "CER cer_Speker_4_Segment_1_large_v2 :=  0.9824561403508771\n",
            "CER cer_Speker_4_Segment_2_large_v2 :=  0.970873786407767\n",
            "\n",
            "CER cer_Speker_4_Segment_1_base :=  0.8070175438596491\n",
            "CER cer_Speker_4_Segment_2_base :=  0.8543689320388349\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qe6kYuF6g0SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5. Спикер №5\n",
        "https://youtu.be/pqp2lOt02YM?si=sk-FQBGY0aQoUQjZ"
      ],
      "metadata": {
        "id": "emsVUgekg1bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначало прослушаем аудио и сделаем ручную транскрипцию."
      ],
      "metadata": {
        "id": "PdNeg484g1cH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "1YjTgbrcg1cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import IPython\n",
        "IPython.display.Audio('Speaker_5_Segment_1.wav')"
      ],
      "metadata": {
        "id": "SaMOv1SQg1cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_5_Segment_1 = ' В мире русской попсы есть большая несправедливость: одних музыкантов помнят и любят, ходят толпой на их стадионные концерты, а других мало вспоминают, редко переслушивают и совершенно не считают культовыми. Почему? Ведь это одинаковая русская попса, которая одинаково играла из всех телерадиоприёмников. '    # Ручная транскрипция спикера 5 и сегмента 1."
      ],
      "metadata": {
        "id": "7WEcnWAMg1cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Audio('Speaker_5_Segment_2.wav')"
      ],
      "metadata": {
        "id": "OYFXluAmg1cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_manual_Speaker_5_Segment_2 = ' Полная жесть. Легенда такая: это самый дорогой клип в истории нашей страны, первый эротический клип, а также первый запрещённый клип, потому что по уверению продюсера \"Фаину\" никогда не показывали по телевизору в полной версии.'    # Ручная транскрипция спикера 5 и сегмента 2."
      ],
      "metadata": {
        "id": "YfTaGbpSg1cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сделаем транскрипцию с whisper."
      ],
      "metadata": {
        "id": "_vOcH5Jjg1cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_5_Segment_1_large_v2, time_Speaker_5_Segment_1_large_v2 = whisper_trans(file_name='Speaker_5_Segment_1.wav')\n",
        "\n",
        "text_Speaker_5_Segment_2_large_v2, time_Speaker_5_Segment_2_large_v2 = whisper_trans(file_name='Speaker_5_Segment_2.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316a6396-0bf5-4994-e5d5-ea7a155d6ce3",
        "id": "pwcvUN_8g1cJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   В мире русской попсы есть большая несправедливость. Одних музыкантов помнят и любят, ходят толпой на их стадионные концерты, а других мало вспоминают, редко переслушивают и совершенно не считают культовыми. Почему? Ведь это одинаковая русская попса, которая одинаково играла из всех телерадиоприемников.\n",
            "Время обработки : 245.07139587402344\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   ПОЛНАЯ ЖЕСТЬ Полная жесть. Легенда такая. Это самый дорогой клип в истории нашей страны. Первый эротический клип, а также первый запрещенный клип, потому что, по уверению продюсера, Фаину никогда не показывали по телевизору в полной версии.\n",
            "Время обработки : 244.74021816253662\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_Speaker_5_Segment_1_base, time_Speaker_5_Segment_1_base = whisper_trans(size='base', file_name='Speaker_5_Segment_1.wav')\n",
        "\n",
        "text_Speaker_5_Segment_2_base, time_Speaker_5_Segment_2_base = whisper_trans(size='base', file_name='Speaker_5_Segment_2.wav')"
      ],
      "metadata": {
        "id": "wJwMzRr5g1cJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ceb57ed-e075-4d43-a86f-6b82eb728023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   В мире русской папсы есть большая несправедливость, одних музыкантов помнит и любят, ходят толпойные, их стадионные концерты, а других мало вспоминают редко переслушивают и совершенно не считают культовыми. Почему? Ведь это одинаковая русская папса, которая одинаково играла из всех теле радиоприемников.\n",
            "Время обработки : 13.50959324836731\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат:   Полная жесть легенда такая – это самый дорогой клип в истории нашей страны первой эратический клип, а также первый запрещенный клип, потому что по уверению продюсера файну никогда не показывали по телевизору в полной версии.\n",
            "Время обработки : 14.498767614364624\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_5_Segment_1  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №5, сегмент 1, модель = \"large_v2\": ', text_Speaker_5_Segment_1_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №5, сегмент 1, модель = \"base\"    : ', text_Speaker_5_Segment_1_base    , end='\\n\\n')\n",
        "\n",
        "print('Ручная транскрипция для данного спикера                        : ', text_manual_Speaker_5_Segment_2  , end='\\n')\n",
        "print('Транскрипция Whisper спикера №5, сегмент 2, модель = \"large_v2\": ', text_Speaker_5_Segment_2_large_v2, end='\\n')\n",
        "print('Транскрипция Whisper спикера №5, сегмент 2, модель = \"base\"    : ', text_Speaker_5_Segment_2_base    , end='\\n\\n')"
      ],
      "metadata": {
        "id": "fohEMrl9g1cK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95c8dc2-54b8-4157-97a6-e1027152b9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ручная транскрипция для данного спикера                        :   В мире русской попсы есть большая несправедливость: одних музыкантов помнят и любят, ходят толпой на их стадионные концерты, а других мало вспоминают, редко переслушивают и совершенно не считают культовыми. Почему? Ведь это одинаковая русская попса, которая одинаково играла из всех телерадиоприёмников. \n",
            "Транскрипция Whisper спикера №5, сегмент 1, модель = \"large_v2\":   В мире русской попсы есть большая несправедливость. Одних музыкантов помнят и любят, ходят толпой на их стадионные концерты, а других мало вспоминают, редко переслушивают и совершенно не считают культовыми. Почему? Ведь это одинаковая русская попса, которая одинаково играла из всех телерадиоприемников.\n",
            "Транскрипция Whisper спикера №5, сегмент 1, модель = \"base\"    :   В мире русской папсы есть большая несправедливость, одних музыкантов помнит и любят, ходят толпойные, их стадионные концерты, а других мало вспоминают редко переслушивают и совершенно не считают культовыми. Почему? Ведь это одинаковая русская папса, которая одинаково играла из всех теле радиоприемников.\n",
            "\n",
            "Ручная транскрипция для данного спикера                        :   Полная жесть. Легенда такая: это самый дорогой клип в истории нашей страны, первый эротический клип, а также первый запрещённый клип, потому что по уверению продюсера \"Фаину\" никогда не показывали по телевизору в полной версии.\n",
            "Транскрипция Whisper спикера №5, сегмент 2, модель = \"large_v2\":   ПОЛНАЯ ЖЕСТЬ Полная жесть. Легенда такая. Это самый дорогой клип в истории нашей страны. Первый эротический клип, а также первый запрещенный клип, потому что, по уверению продюсера, Фаину никогда не показывали по телевизору в полной версии.\n",
            "Транскрипция Whisper спикера №5, сегмент 2, модель = \"base\"    :   Полная жесть легенда такая – это самый дорогой клип в истории нашей страны первой эратический клип, а также первый запрещенный клип, потому что по уверению продюсера файну никогда не показывали по телевизору в полной версии.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь посчитаем метрики Word Error Rate и Character Error Rate."
      ],
      "metadata": {
        "id": "5hEUv94ag1cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_Speker_5_Segment_1_large_v2 = calculate_wer(reference=text_manual_Speaker_5_Segment_1, hypothesis=text_Speaker_5_Segment_1_large_v2)\n",
        "wer_Speker_5_Segment_2_large_v2 = calculate_wer(reference=text_manual_Speaker_5_Segment_2, hypothesis=text_Speaker_5_Segment_2_large_v2)\n",
        "\n",
        "wer_Speker_5_Segment_1_base = calculate_wer(reference=text_manual_Speaker_5_Segment_1, hypothesis=text_Speaker_5_Segment_1_base)\n",
        "wer_Speker_5_Segment_2_base = calculate_wer(reference=text_manual_Speaker_5_Segment_2, hypothesis=text_Speaker_5_Segment_2_base)"
      ],
      "metadata": {
        "id": "Jr71LKLEg1cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cer_Speker_5_Segment_1_large_v2 = calculate_cer(reference=text_manual_Speaker_5_Segment_1, hypothesis=text_Speaker_5_Segment_1_large_v2)\n",
        "\n",
        "cer_Speker_5_Segment_2_large_v2 = calculate_cer(reference=text_manual_Speaker_5_Segment_2, hypothesis=text_Speaker_5_Segment_2_large_v2)\n",
        "\n",
        "\n",
        "cer_Speker_5_Segment_1_base = calculate_cer(reference=text_manual_Speaker_5_Segment_1, hypothesis=text_Speaker_5_Segment_1_base)\n",
        "\n",
        "cer_Speker_5_Segment_2_base = calculate_cer(reference=text_manual_Speaker_5_Segment_2, hypothesis=text_Speaker_5_Segment_2_base)\n"
      ],
      "metadata": {
        "id": "_tbM6ub6g1cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Error Rate\n",
        "print('WER cer_Speker_5_Segment_1_large_v2 := ', wer_Speker_5_Segment_1_large_v2, end='\\n')\n",
        "print('WER cer_Speker_5_Segment_2_large_v2 := ', wer_Speker_5_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('WER cer_Speker_5_Segment_1_base := ', wer_Speker_5_Segment_1_base, end='\\n')\n",
        "print('WER cer_Speker_5_Segment_2_base := ', wer_Speker_5_Segment_2_base, end='\\n\\n')\n",
        "\n",
        "#Character Error Rate\n",
        "print('CER cer_Speker_5_Segment_1_large_v2 := ', cer_Speker_5_Segment_1_large_v2, end='\\n')\n",
        "print('CER cer_Speker_5_Segment_2_large_v2 := ', cer_Speker_5_Segment_2_large_v2, end='\\n\\n')\n",
        "\n",
        "print('CER cer_Speker_5_Segment_1_base := ', cer_Speker_5_Segment_1_base, end='\\n')\n",
        "print('CER cer_Speker_5_Segment_2_base := ', cer_Speker_5_Segment_2_base, end='\\n\\n')"
      ],
      "metadata": {
        "id": "zJtuR_Avg1cK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408972e5-bd00-4c8d-8aea-f93fe56395fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER cer_Speker_5_Segment_1_large_v2 :=  0.07317073170731707\n",
            "WER cer_Speker_5_Segment_2_large_v2 :=  1.0\n",
            "\n",
            "WER cer_Speker_5_Segment_1_base :=  0.7560975609756098\n",
            "WER cer_Speker_5_Segment_2_base :=  0.9705882352941176\n",
            "\n",
            "CER cer_Speker_5_Segment_1_large_v2 :=  0.019672131147540985\n",
            "CER cer_Speker_5_Segment_2_large_v2 :=  0.9956140350877193\n",
            "\n",
            "CER cer_Speker_5_Segment_1_base :=  0.2459016393442623\n",
            "CER cer_Speker_5_Segment_2_base :=  0.7456140350877193\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DKOI9Loxg1cL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}